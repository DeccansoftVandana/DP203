{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Read data from data lake (Ensure that you have Employee.txt in DataLake)\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import *\n",
        "account_name = \"dssdemomtbanklake\"\n",
        "container_name = \"taxidata\"\n",
        "relative_path = \"Your path\"\n",
        "adls_path = 'abfss://%s@%s.dfs.core.windows.net/' % (container_name, account_name)\n",
        "\n",
        "spark.conf.set(\"fs.azure.account.auth.type.%s.dfs.core.windows.net\" %account_name, \"SharedKey\")\n",
        "spark.conf.set(\"fs.azure.account.key.%s.dfs.core.windows.net\" %account_name ,\"41FJwKc3BxUGnPBKWilgzJBndg/R9Z6rMcHm+VCmf4noPFEAgdzBqGO4rRDV4CgFhYwPaalDgiBK+AStGoYV2w==\")\n",
        "\n",
        "df1 = spark.read.option('header', 'true') \\\n",
        "                .option('delimiter', ',') \\\n",
        "                .csv(adls_path + '/Employee.txt')\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "microsoft": {}
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Read data from Azure Storage (Ensure that you have orders-2013.txt in blob)\r\n",
        "\r\n",
        "from pyspark.sql import SparkSession\r\n",
        "from pyspark.sql.types import *\r\n",
        "\r\n",
        "blob_account_name = \"dssdemomtbanksa\"\r\n",
        "blob_container_name = \"orders\"\r\n",
        "blob_relative_path = \"orders-2013.txt\"\r\n",
        "blob_sas_token = \"sp=r&st=2023-06-09T09:55:16Z&se=2023-10-06T17:55:16Z&spr=https&sv=2022-11-02&sr=b&sig=vKDBMBs5EWByp2aJQ6pzmtjkbhj7MrejTajws%2BF2zho%3D\"\r\n",
        "\r\n",
        "wasbs_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path)\r\n",
        "spark.conf.set('fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name), blob_sas_token)\r\n",
        "\r\n",
        "order_df = spark.read.option(\"header\", \"true\") \\\r\n",
        "            .option(\"delimiter\",\"\\t\") \\\r\n",
        "            .csv(wasbs_path)\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "order_df.show(10)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%pyspark\r\n",
        "#Read data from primary adls storage\r\n",
        "prod_df = spark.read.load('abfss://synapase-files@mtbanklake1234.dfs.core.windows.net/data/products.csv', format='csv'\r\n",
        "## If header exists uncomment line below\r\n",
        ",## header=True\r\n",
        ")\r\n",
        "display(prod_df.limit(10))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "microsoft": {
          "language": "python"
        },
        "collapsed": false
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}